{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "import operator\n",
    "import numpy as np\n",
    "from scipy.special import betaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 1\n",
    "if dataset==0:\n",
    "    # MovieLens-1M dataset\n",
    "    ratings_file = '../data/ml-1m/ratings.dat'\n",
    "    delimiter = '::'\n",
    "elif dataset==1:\n",
    "    # MovieLens-100k dataset\n",
    "    ratings_file = '../data/ml-100k/u.data'\n",
    "    delimiter = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_1_m():\n",
    "    ratings = open(ratings_file, 'r').read().split('\\n')\n",
    "    user_item_map = {}\n",
    "    for r in ratings:\n",
    "        attrs = r.split(delimiter)\n",
    "        if len(attrs) < 4:\n",
    "            continue\n",
    "        user = 'u' + attrs[0]\n",
    "        item = 'i' + attrs[1]\n",
    "        rating = int(attrs[2])\n",
    "        if user in user_item_map:\n",
    "            user_item_map[user][item] = rating\n",
    "        else:\n",
    "            user_item_map[user] = {}\n",
    "            user_item_map[user][item] = rating\n",
    "    for user in user_item_map:\n",
    "        sum = 0\n",
    "        for item in user_item_map[user]:\n",
    "            sum += user_item_map[user][item]\n",
    "        avg_rating_user = sum * 1.0 / len(user_item_map[user])\n",
    "        for item in user_item_map[user]:\n",
    "            if user_item_map[user][item] >= avg_rating_user:\n",
    "                user_item_map[user][item] = 1\n",
    "            else:\n",
    "                user_item_map[user][item] = 0\n",
    "    for user in user_item_map:\n",
    "        if len(user_item_map[user]) < 10:\n",
    "            del user_item_map[user]\n",
    "    return user_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_graph(user_item_map):\n",
    "    graph = {}\n",
    "    for user in user_item_map:\n",
    "        if user not in graph:\n",
    "            graph[user] = set([])\n",
    "        for item in user_item_map[user]:\n",
    "            if item not in graph:\n",
    "                graph[item] = set([])\n",
    "            graph[user].add(item)\n",
    "            graph[item].add(user)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    while True:\n",
    "        changed = False\n",
    "        delete_nodes = []\n",
    "        for node in graph:\n",
    "            if len(graph[node]) < 10:\n",
    "                changed = True\n",
    "                delete_nodes.append(node)\n",
    "        for node in delete_nodes:\n",
    "            del graph[node]\n",
    "        for node1 in graph:\n",
    "            delete_nodes = []\n",
    "            for node2 in graph[node1]:\n",
    "                if node2 not in graph:\n",
    "                    changed = True\n",
    "                    delete_nodes.append(node2)\n",
    "            for node2 in delete_nodes:\n",
    "                graph[node1].remove(node2)\n",
    "        if not changed:\n",
    "            break\n",
    "    for node in graph:\n",
    "        graph[node] = list(graph[node])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_ratings(user_item_map):\n",
    "    item_rating_map = {}\n",
    "    for user in user_item_map:\n",
    "        for item in user_item_map[user]:\n",
    "            if item not in item_rating_map:\n",
    "                item_rating_map[item] = [1, 1]\n",
    "            if user_item_map[user][item] == 0:\n",
    "                item_rating_map[item][1] += 1\n",
    "            else:\n",
    "                item_rating_map[item][0] += 1\n",
    "    return item_rating_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_item_map = load_1_m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_rating_map = get_num_ratings(user_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = form_graph(user_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = clean_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split MovieLens-100k data so that for each user, 80% is training, 20% is for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i148', 'i149', 'i142', 'i143', 'i140', 'i141', 'i146', 'i147', 'i144', 'i145', 'i177', 'i229', 'i118', 'i228', 'i270', 'i271', 'i272', 'i89', 'i205', 'i82', 'i83', 'i80', 'i81', 'i86', 'i87', 'i84', 'i85', 'i153', 'i97', 'i259', 'i193', 'i77', 'i76', 'i73', 'i72', 'i71', 'i70', 'i189', 'i79', 'i78', 'i204', 'i252', 'i158', 'i263', 'i262', 'i261', 'i260', 'i266', 'i265', 'i264', 'i269', 'i268']\n"
     ]
    }
   ],
   "source": [
    "first_20percent_of_u1 = [graph['u1'][i] for i in range(int(0.2*len(graph['u1'])))] \n",
    "print first_20percent_of_u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph['u1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i143'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['u1'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: a graph called g\n",
    "# Output: two test sets, one containing 20% of g's items per user, \n",
    "#         the other containing 80% \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_sets(g): \n",
    "    test_set = defaultdict(list) \n",
    "    training_set = defaultdict(list)\n",
    "    \n",
    "    for key in g:\n",
    "        if key[0]=='u': \n",
    "            # For length of items belonging to that key, split 20% and 80%\n",
    "            first_20 = int(0.2*len(g[key]))\n",
    "            \n",
    "            for i in range(first_20): \n",
    "                test_set[key].append(g[key][i])\n",
    "\n",
    "            for j in range(first_20, len(g[key])):\n",
    "                training_set[key].append(g[key][j])\n",
    "            \n",
    "    for user in test_set.keys():\n",
    "        for item in test_set[user]:\n",
    "            test_set[item].append(user)\n",
    "            \n",
    "    for user in training_set.keys(): \n",
    "        for item in training_set[user]: \n",
    "            training_set[item].append(user)\n",
    "            \n",
    "    return test_set, training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set, training_set = create_sets(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print first_20percent_of_u1 == test_set['u1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_100k_test_set has  1833 keys\n",
      "movie_100k_training_set has  2094  keys\n"
     ]
    }
   ],
   "source": [
    "print \"movie_100k_test_set has \", len(test_set.keys()), \"keys\"\n",
    "print \"movie_100k_training_set has \", len(training_set.keys()), \" keys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_user_similarity(graph):\n",
    "    users = []\n",
    "    for key in graph:\n",
    "        if 'u' in key:\n",
    "            users.append(key)\n",
    "    similarity = np.zeros((len(users) + 1, len(users) + 1))\n",
    "    count = np.zeros((len(users) + 1, len(users) + 1))\n",
    "    np.fill_diagonal(similarity, 1)\n",
    "    np.fill_diagonal(count, 1)\n",
    "    for u1 in users:\n",
    "        for u2 in users:\n",
    "            if u1 == u2:\n",
    "                continue\n",
    "            for item in graph[u1]:\n",
    "                if item in graph[u2]:\n",
    "                    count[int(u1[1:]), int(u2[1:])] += 1\n",
    "                    if user_item_map[u1][item] == user_item_map[u2][item]:\n",
    "                        similarity[int(u1[1:]), int(u2[1:])] += 1\n",
    "                    else:\n",
    "                        similarity[int(u1[1:]), int(u2[1:])] -= 1\n",
    "            count[int(u2[1:]), int(u1[1:])] = count[int(u1[1:]), int(u2[1:])]\n",
    "            similarity[int(u2[1:]), int(u1[1:])] = similarity[int(u1[1:]), int(u2[1:])]\n",
    "    return np.divide(similarity, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "user_similarity = find_user_similarity(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_similarity[np.isnan(user_similarity)] = 0\n",
    "min_value = user_similarity.min()\n",
    "max_value = user_similarity.max()\n",
    "user_similarity = (user_similarity - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543638681413\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print len(np.argwhere(user_similarity[:, :] > 0.5)) * 1.0 / (944**2)\n",
    "print min_value\n",
    "print max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIS_map = {}\n",
    "PPS_map = {}\n",
    "PORS_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PIS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    total = 0\n",
    "    for i in range(0,item_rating_map[item2][0]):\n",
    "        total += np.exp(betaln(item_rating_map[item1][0]+i,item_rating_map[item1][1]+item_rating_map[item2][1]) -\\\n",
    "                        np.log(item_rating_map[item2][1]+i) - \\\n",
    "                        betaln(1+i, item_rating_map[item2][1]) -\\\n",
    "                        betaln(item_rating_map[item1][0],item_rating_map[item1][1])\n",
    "                       )\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PPS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    p1 = (item_rating_map[item1][0]) * 1.0 / (item_rating_map[item1][0] + item_rating_map[item1][1])\n",
    "    p2 = (item_rating_map[item2][0]) * 1.0 / (item_rating_map[item2][0] + item_rating_map[item2][1])\n",
    "    return p1 * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PORS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    o1 = (item_rating_map[item1][0]) * 1.0 / (item_rating_map[item1][1])\n",
    "    o2 = (item_rating_map[item2][0]) * 1.0 / (item_rating_map[item2][1])\n",
    "    return o2 / o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def USS(u1, i1, u2, i2):\n",
    "    reliability = item_rating_map[int(i2[1:])][0] * 1.0 / (item_rating_map[int(i2[1:])][0] + item_rating_map[int(i2[1:])][1])\n",
    "    indicator = 1\n",
    "    if user_item_map[int(u2[1:])][int(i2[1:])] == 0:\n",
    "        indicator = 0\n",
    "    similarity = user_similarity[int(u1[1:]), int(u2[1:])]\n",
    "    return reliability * similarity * indicator + reliability * (1.0 - similarity) * (1 - indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(graph, target_user):\n",
    "    score_PIS = {}\n",
    "    score_PPS = {}\n",
    "    score_PORS = {}\n",
    "    score_USS = {}\n",
    "    PIS_values = {}\n",
    "    PPS_values = {}\n",
    "    PORS_values = {}\n",
    "    USS_values = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(graph, target_user):\n",
    "    score_map_PPS = {}\n",
    "    score_map_PORS = {}\n",
    "    score_map_PIS = {}\n",
    "    score_map_user_similarity = {}\n",
    "    for primary_item in graph[target_user]:\n",
    "        score_map_PPS[primary_item] = 0.0\n",
    "        score_map_PORS[primary_item] = 0.0\n",
    "        score_map_PIS[primary_item] = 0.0\n",
    "        for secondary_user in graph[primary_item]:\n",
    "            if secondary_user == target_user:\n",
    "                continue\n",
    "            for secondary_item in graph[secondary_user]:\n",
    "                if secondary_item in graph[target_user]:\n",
    "                    continue\n",
    "                if (primary_item, secondary_item) in PIS_map:\n",
    "                    score_map_PIS[primary_item] += PIS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PIS_map[(primary_item, secondary_item)] = PIS((primary_item, secondary_item))\n",
    "                    score_map_PIS[primary_item] += PIS_map[(primary_item, secondary_item)]\n",
    "                if (primary_item, secondary_item) in PPS_map:\n",
    "                    score_map_PPS[primary_item] += PPS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PPS_map[(primary_item, secondary_item)] = PPS((primary_item, secondary_item))\n",
    "                    score_map_PPS[primary_item] += PPS_map[(primary_item, secondary_item)]\n",
    "                if (primary_item, secondary_item) in PORS_map:\n",
    "                    score_map_PORS[primary_item] += PORS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PORS_map[(primary_item, secondary_item)] = PORS((primary_item, secondary_item))\n",
    "                    score_map_PORS[primary_item] += PORS_map[(primary_item, secondary_item)]\n",
    "                if (secondary_user, secondary_item) in score_map_user_similarity:\n",
    "                    s\n",
    "                x = user_similarity_score(target_user, primary_item, secondary_user, secondary_item)\n",
    "    return score_map_PIS, score_map_PPS, score_map_PORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ranking = rank(graph, 'u1')\n",
    "rank(training_set, 'u1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking_PIS = ranking[0]\n",
    "ranking_PPS = ranking[1]\n",
    "ranking_PORS = ranking[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_1 = sorted(ranking_PIS.items(), key=operator.itemgetter(1))\n",
    "sorted_2 = sorted(ranking_PPS.items(), key=operator.itemgetter(1))\n",
    "sorted_3 = sorted(ranking_PORS.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print sorted_1[:5]\n",
    "print sorted_2[:5]\n",
    "print sorted_3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ranking_PIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 3 lists of ranking scores per item for PIS, PPS, PORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ******Caution: the code in this box will need to run overnight due to the size of the test_set****** \n",
    "\n",
    "# Input:  One of the score dictionaries generated by calling rank(graph, key) \n",
    "# Output: A ranking list for each user, where the most highly recommended items come first (no need to store\n",
    "#         the score that was associated with that item)\n",
    "def generate_ranking_list(score): \n",
    "    ranking_list = {} \n",
    "\n",
    "    for user in score: \n",
    "        # Sort the score list for that user \n",
    "        sorted_score = sorted(score[user].items(), key=operator.itemgetter(1), reverse=True)\n",
    "        ranking_list[user]= [item[0] for item in sorted_score]\n",
    "\n",
    "    return ranking_list \n",
    "\n",
    "# For each of the 3 methods, generate scores as a dictionary where \n",
    "# Key = User, Value = List of (item,score) pairs \n",
    "score_PIS = {} \n",
    "score_PPS = {} \n",
    "score_PORS = {}\n",
    "score_user_similarity = {}\n",
    "\n",
    "for user in training_set: \n",
    "    if user[0] == 'u':\n",
    "        score_PIS[user], score_PPS[user], score_PORS[user], score_user_similarity = rank(graph, key)\n",
    "        \n",
    "# Generate 3 lists of ranking scores per item for PIS, PPS, PORS\n",
    "ranking_PIS = generate_ranking_list(score_PIS)\n",
    "ranking_PPS = generate_ranking_list(score_PPS)\n",
    "ranking_PORS = generate_ranking_list(score_PORS)\n",
    "ranking_user_similarity = generate_ranking_list(score_user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lp_ln(predictions):\n",
    "    lp = defaultdict{list}\n",
    "    ln = defaultdict{list}\n",
    "    for user in predictions:\n",
    "        for item in testing_set[user]:\n",
    "            if user_item_map[user][item] == 1:\n",
    "                lp[user].append(item)\n",
    "            else:\n",
    "                ln[user].append(item)\n",
    "    return lp,ln\n",
    "\n",
    "def p_at_k(k, predictions, lp):\n",
    "    patk = 0.0\n",
    "    for user in predictions:\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            if predictions[user][i] in lp[user]:\n",
    "                correct+=1\n",
    "        patk += 1.0*correct/k\n",
    "    return patk/len(predictions.keys())\n",
    "\n",
    "def MAP(predictions, lp):\n",
    "    MAP = 0.0\n",
    "    for user in predictions:\n",
    "        umap = 0.0\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp:\n",
    "                correct += 1\n",
    "                umap += 1.0*correct/(i*len(lp[user]))\n",
    "    MAP += umap\n",
    "    return MAP/len(predictions.keys())\n",
    "\n",
    "def MRR(predictions, lp):\n",
    "    MRR = 0.0\n",
    "    for user in predictions:\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp:\n",
    "                MRR += 1.0/i\n",
    "                break\n",
    "    return MRR/len(predictions.keys())\n",
    "\n",
    "def rel(item, u_lp, u_ln):\n",
    "    if item in u_lp:\n",
    "        return 2\n",
    "    elif item in u_ln:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def dcg_at_n(n, u_pred, u_lp, u_ln):\n",
    "    u_dcg = 0.0\n",
    "    for i in range(n):\n",
    "        if i==0:\n",
    "            u_dcg += rel(u_pred[i], u_lp, u_ln)\n",
    "        else:\n",
    "            u_dcg += rel(u_pred[i], u_lp, u_ln)/np.log2(i)\n",
    "    return u_dcg\n",
    "    \n",
    "def idcg_at_n(n, u_pred, u_lp, u_ln):\n",
    "    rel_scores = []\n",
    "    for item in u_pred:\n",
    "        rel_scores.append(rel(item, u_lp, u_ln))\n",
    "    rel_scores = sorted(rel_scores, reverse=True)\n",
    "    u_idcg = rel_scores[0]\n",
    "    for i in range(1,len(rel_scores)):\n",
    "        u_idcg += rel_scores[i]/np.log2(i)\n",
    "    return u_idcg\n",
    "        \n",
    "def ndcg_at_n(n, predictions, lp, ln):\n",
    "    ndcg = 0.0\n",
    "    for user in predictions:\n",
    "        u_dcg = dcg_at_n(n, predictions[user], lp[user], ln[user])\n",
    "        u_idcg = idcg_at_n(n, predictions[user], lp[user], ln[user])\n",
    "        ndcg += u_dcg/u_idcg\n",
    "    return ndcg/len(predictions.keys())\n",
    "\n",
    "k = 10\n",
    "n = 10\n",
    "lp, ln = get_lp_ln(predictions)\n",
    "print p_at_k(k, predictions, lp)\n",
    "print MAP(predictions, lp)\n",
    "print MRR(predictions, lp)\n",
    "print ndcg_at_n(n, predictions, lp, ln)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
