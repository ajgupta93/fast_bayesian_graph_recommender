{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "import operator\n",
    "import numpy as np\n",
    "from scipy.special import betaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 1\n",
    "if dataset==0:\n",
    "    # MovieLens-1M dataset\n",
    "    ratings_file = '../data/ml-1m/ratings.dat'\n",
    "    delimiter = '::'\n",
    "elif dataset==1:\n",
    "    # MovieLens-100k dataset\n",
    "    ratings_file = '../data/ml-100k/u.data'\n",
    "    delimiter = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_1_m():\n",
    "    ratings = open(ratings_file, 'r').read().split('\\n')\n",
    "    user_item_map = {}\n",
    "    for r in ratings:\n",
    "        attrs = r.split(delimiter)\n",
    "        if len(attrs) < 4:\n",
    "            continue\n",
    "        user = int(attrs[0])\n",
    "        item = int(attrs[1])\n",
    "        rating = int(attrs[2])\n",
    "        if user in user_item_map:\n",
    "            user_item_map[user][item] = rating\n",
    "        else:\n",
    "            user_item_map[user] = {}\n",
    "            user_item_map[user][item] = rating\n",
    "    for user in user_item_map:\n",
    "        sum = 0\n",
    "        for item in user_item_map[user]:\n",
    "            sum += user_item_map[user][item]\n",
    "        avg_rating_user = sum * 1.0 / len(user_item_map[user])\n",
    "        for item in user_item_map[user]:\n",
    "            if user_item_map[user][item] >= avg_rating_user:\n",
    "                user_item_map[user][item] = 1\n",
    "            else:\n",
    "                user_item_map[user][item] = 0\n",
    "    for user in user_item_map:\n",
    "        if len(user_item_map[user]) < 10:\n",
    "            del user_item_map[user]\n",
    "    return user_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_graph(user_item_map):\n",
    "    graph = {}\n",
    "    for user in user_item_map:\n",
    "        if 'u' + str(user) not in graph:\n",
    "            graph['u' + str(user)] = set([])\n",
    "        for item in user_item_map[user]:\n",
    "            if 'i' + str(item) not in graph:\n",
    "                graph['i' + str(item)] = set([])\n",
    "            graph['u' + str(user)].add('i' + str(item))\n",
    "            graph['i' + str(item)].add('u' + str(user))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    while True:\n",
    "        changed = False\n",
    "        delete_nodes = []\n",
    "        for node in graph:\n",
    "            if len(graph[node]) < 10:\n",
    "                changed = True\n",
    "                delete_nodes.append(node)\n",
    "        for node in delete_nodes:\n",
    "            del graph[node]\n",
    "        for node1 in graph:\n",
    "            delete_nodes = []\n",
    "            for node2 in graph[node1]:\n",
    "                if node2 not in graph:\n",
    "                    changed = True\n",
    "                    delete_nodes.append(node2)\n",
    "            for node2 in delete_nodes:\n",
    "                graph[node1].remove(node2)\n",
    "        if not changed:\n",
    "            break\n",
    "    for node in graph:\n",
    "        graph[node] = list(graph[node])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_ratings(user_item_map):\n",
    "    item_rating_map = {}\n",
    "    for user in user_item_map:\n",
    "        for item in user_item_map[user]:\n",
    "            if item not in item_rating_map:\n",
    "                item_rating_map[item] = [1, 1]\n",
    "            if user_item_map[user][item] == 0:\n",
    "                item_rating_map[item][1] += 1\n",
    "            else:\n",
    "                item_rating_map[item][0] += 1\n",
    "    return item_rating_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_item_map = load_1_m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_rating_map = get_num_ratings(user_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = form_graph(user_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = clean_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split MovieLens-100k data so that for each user, 80% is training, 20% is for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i148', 'i149', 'i142', 'i143', 'i140', 'i141', 'i146', 'i147', 'i144', 'i145', 'i177', 'i233', 'i229', 'i228', 'i270', 'i235', 'i88', 'i89', 'i205', 'i82', 'i83', 'i80', 'i81', 'i86', 'i87', 'i84', 'i85', 'i258', 'i259', 'i77', 'i76', 'i73', 'i72', 'i71', 'i70', 'i220', 'i79', 'i78', 'i252', 'i253', 'i212', 'i207', 'i218', 'i260', 'i266', 'i265', 'i264', 'i269', 'i268', 'i249', 'i64', 'i65']\n"
     ]
    }
   ],
   "source": [
    "first_20percent_of_u1 = [graph['u1'][i] for i in range(int(0.2*len(graph['u1'])))] \n",
    "print first_20percent_of_u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph['u1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i143'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['u1'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: a graph called g\n",
    "# Output: two test sets, one containing 20% of g's items per user, \n",
    "#         the other containing 80% \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_sets(g): \n",
    "    test_set = defaultdict(list) \n",
    "    training_set = defaultdict(list)\n",
    "    \n",
    "    for key in g:\n",
    "        if key[0]=='u': \n",
    "            # For length of items belonging to that key, split 20% and 80%\n",
    "            first_20 = int(0.2*len(g[key]))\n",
    "            \n",
    "            for i in range(first_20): \n",
    "                test_set[key].append(g[key][i])\n",
    "\n",
    "            for j in range(first_20, len(g[key])):\n",
    "                training_set[key].append(g[key][j])\n",
    "            \n",
    "    for user in test_set.keys():\n",
    "        for item in test_set[user]:\n",
    "            test_set[item].append(user)\n",
    "            \n",
    "    for user in training_set.keys(): \n",
    "        for item in training_set[user]: \n",
    "            training_set[item].append(user)\n",
    "            \n",
    "    return test_set, training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set, training_set = create_sets(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print first_20percent_of_u1 == test_set['u1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_100k_test_set has  1805 keys\n",
      "movie_100k_training_set has  2091  keys\n"
     ]
    }
   ],
   "source": [
    "print \"movie_100k_test_set has \", len(test_set.keys()), \"keys\"\n",
    "print \"movie_100k_training_set has \", len(training_set.keys()), \" keys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_user_similarity(graph):\n",
    "    users = []\n",
    "    for key in graph:\n",
    "        if 'u' in key:\n",
    "            users.append(key)\n",
    "    similarity = np.zeros((len(users) + 1, len(users) + 1))\n",
    "    count = np.zeros((len(users) + 1, len(users) + 1))\n",
    "    np.fill_diagonal(similarity, 1)\n",
    "    np.fill_diagonal(count, 1)\n",
    "    for i in xrange(len(users)):\n",
    "        for j in xrange(len(users)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            u1 = int(users[i][1:])\n",
    "            u2 = int(users[j][1:])\n",
    "            for item in graph[users[i]]:\n",
    "                if item in graph[users[j]]:\n",
    "                    item_no = int(item[1:])\n",
    "                    count[u1, u2] += 1\n",
    "                    if user_item_map[u1][item_no] == user_item_map[u2][item_no]:\n",
    "                        similarity[u1, u2] += 1\n",
    "                    else:\n",
    "                        similarity[u1, u2] -= 1\n",
    "            count[u2, u1] = count[u1, u2]\n",
    "            similarity[u2, u1] = similarity[u1, u2]\n",
    "    return np.divide(similarity, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "user_similarity = find_user_similarity(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_similarity[np.isnan(user_similarity)] = 0\n",
    "min_value = user_similarity.min()\n",
    "max_value = user_similarity.max()\n",
    "user_similarity = (user_similarity - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0972803253375\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print len(np.argwhere(user_similarity[:, :] == 1.0)) * 1.0 / (944**2)\n",
    "print min_value\n",
    "print max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891136"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIS_map = {}\n",
    "PPS_map = {}\n",
    "PORS_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PIS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    total = 0\n",
    "    for i in range(0,item_rating_map[item2][0]-1):\n",
    "        total += np.exp(betaln(item_rating_map[item1][0]+i,item_rating_map[item1][1]+item_rating_map[item2][1]) -\\\n",
    "                        np.log(item_rating_map[item2][1]+i) - \\\n",
    "                        betaln(1+i, item_rating_map[item2][1]) -\\\n",
    "                        betaln(item_rating_map[item1][0],item_rating_map[item1][1])\n",
    "                       )\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PPS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    p1 = (item_rating_map[item1][0]) * 1.0 / (item_rating_map[item1][0] + item_rating_map[item1][1])\n",
    "    p2 = (item_rating_map[item2][0]) * 1.0 / (item_rating_map[item2][0] + item_rating_map[item2][1])\n",
    "    return p1 * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PORS(item_pair):\n",
    "    item1 = int(item_pair[0][1:])\n",
    "    item2 = int(item_pair[1][1:])\n",
    "    o1 = (item_rating_map[item1][0]) * 1.0 / (item_rating_map[item1][1])\n",
    "    o2 = (item_rating_map[item2][0]) * 1.0 / (item_rating_map[item2][1])\n",
    "    return o2 / o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_score(u1, i1, u2, i2):\n",
    "    reliability = item_rating_map[int(i2[1:])][0] * 1.0 / (item_rating_map[int(i2[1:])][0] + item_rating_map[int(i2[1:])][1])\n",
    "    indicator = 1\n",
    "    if user_item_map[int(u2[1:])][int(i2[1:])] == 0:\n",
    "        indicator = 0\n",
    "    similarity = user_similarity[int(u1[1:]), int(u2[1:])]\n",
    "    return reliability * similarity * indicator + reliability * (1.0 - similarity) * (1 - indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(graph, target_user):\n",
    "    score_map_PPS = {}\n",
    "    score_map_PORS = {}\n",
    "    score_map_PIS = {}\n",
    "    for primary_item in graph[target_user]:\n",
    "        score_map_PPS[primary_item] = 0.0\n",
    "        score_map_PORS[primary_item] = 0.0\n",
    "        score_map_PIS[primary_item] = 0.0\n",
    "        for secondary_user in graph[primary_item]:\n",
    "            if secondary_user == target_user:\n",
    "                continue\n",
    "            for secondary_item in graph[secondary_user]:\n",
    "                if secondary_item in graph[target_user]:\n",
    "                    continue\n",
    "                '''if (primary_item, secondary_item) in PIS_map:\n",
    "                    score_map_PIS[primary_item] += PIS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PIS_map[(primary_item, secondary_item)] = PIS((primary_item, secondary_item))\n",
    "                    score_map_PIS[primary_item] += PIS_map[(primary_item, secondary_item)]\n",
    "                if (primary_item, secondary_item) in PPS_map:\n",
    "                    score_map_PPS[primary_item] += PPS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PPS_map[(primary_item, secondary_item)] = PPS((primary_item, secondary_item))\n",
    "                    score_map_PPS[primary_item] += PPS_map[(primary_item, secondary_item)]\n",
    "                if (primary_item, secondary_item) in PORS_map:\n",
    "                    score_map_PORS[primary_item] += PORS_map[(primary_item, secondary_item)]\n",
    "                else:\n",
    "                    PORS_map[(primary_item, secondary_item)] = PORS((primary_item, secondary_item))\n",
    "                    score_map_PORS[primary_item] += PORS_map[(primary_item, secondary_item)]'''\n",
    "                x = user_score(target_user, primary_item, secondary_user, secondary_item)\n",
    "                print x\n",
    "    #return score_map_PIS, score_map_PPS, score_map_PORS\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ranking = rank(graph, 'u1')\n",
    "rank(training_set, 'u1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking_PIS = ranking[0]\n",
    "ranking_PPS = ranking[1]\n",
    "ranking_PORS = ranking[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_1 = sorted(ranking_PIS.items(), key=operator.itemgetter(1))\n",
    "sorted_2 = sorted(ranking_PPS.items(), key=operator.itemgetter(1))\n",
    "sorted_3 = sorted(ranking_PORS.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print sorted_1[:5]\n",
    "print sorted_2[:5]\n",
    "print sorted_3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ranking_PIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 3 lists of ranking scores per item for PIS, PPS, PORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ******Caution: the code in this box will need to run overnight due to the size of the test_set****** \n",
    "\n",
    "# Input:  One of the score dictionaries generated by calling rank(graph, key) \n",
    "# Output: A ranking list for each user, where the most highly recommended items come first (no need to store\n",
    "#         the score that was associated with that item)\n",
    "def generate_ranking_list(score): \n",
    "    ranking_list = {} \n",
    "\n",
    "    for user in score: \n",
    "        # Sort the score list for that user \n",
    "        sorted_score = sorted(score[user].items(), key=operator.itemgetter(1), reverse=True)\n",
    "        ranking_list[user]= [item[0] for item in sorted_score]\n",
    "\n",
    "    return ranking_list \n",
    "\n",
    "# For each of the 3 methods, generate scores as a dictionary where \n",
    "# Key = User, Value = List of (item,score) pairs \n",
    "score_PIS = {} \n",
    "score_PPS = {} \n",
    "score_PORS = {}\n",
    "\n",
    "for user in training_set: \n",
    "    if user[0] == 'u':\n",
    "        score_PIS[user], score_PPS[user], score_PORS[user] = rank(graph, key)\n",
    "        \n",
    "# Generate 3 lists of ranking scores per item for PIS, PPS, PORS\n",
    "ranking_PIS = generate_ranking_list(score_PIS)\n",
    "ranking_PPS = generate_ranking_list(score_PPS)\n",
    "ranking_PORS = generate_ranking_list(score_PORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lp_ln(gt):\n",
    "    lp = defaultdict{}\n",
    "    ln = defaultdict{}\n",
    "    for user in gt:\n",
    "        if 'u' in user:\n",
    "            for item in gt[user]:\n",
    "                if user_item_map[user][item] == 1:\n",
    "                    lp[user].append(item)\n",
    "                else:\n",
    "                    ln[user].append(item)\n",
    "    return lp,ln\n",
    "\n",
    "def p_at_k(k, predictions, lp):\n",
    "    patk = 0.0\n",
    "    for user in predictions:\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            if predictions[user][i] in lp[user]:\n",
    "                correct+=1\n",
    "        patk += 1.0*correct/k\n",
    "    return patk/len(predictions.keys())\n",
    "\n",
    "def MAP(predictions, lp):\n",
    "    MAP = 0.0\n",
    "    for user in predictions:\n",
    "        umap = 0.0\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp:\n",
    "                correct += 1\n",
    "                umap += correct/(i*len(lp[user]))\n",
    "    MAP += umap\n",
    "    return MAP/len(predictions.keys())\n",
    "\n",
    "def MRR(users, predictions, lp):\n",
    "    MRR = 0.0\n",
    "    for user in predictions:\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp:\n",
    "                MRR += 1.0/i\n",
    "                break\n",
    "    return MRR/len(predictions.keys())\n",
    "\n",
    "def rel(item, lp, ln):\n",
    "    if item in lp:\n",
    "        return 2\n",
    "    elif item in ln:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
